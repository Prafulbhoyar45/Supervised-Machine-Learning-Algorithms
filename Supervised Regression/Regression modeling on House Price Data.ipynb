{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8c9351",
   "metadata": {},
   "source": [
    "<table align=\"center\" width=100%>\n",
    "    <tr>\n",
    "        </td>\n",
    "            </td>\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"center\">\n",
    "                <font color=\"#21618C\" size=8px>\n",
    "                    <b> Regression modeling on House Price Data\n",
    "                    </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc13502",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "This dataset is created for the prediction of House Prices from an Indian perspective Towns. The dataset contains various features that are important during the application for the selling the Houses. The predicted output obtained from the classification algorithm gives a fair idea about the chances of a Houses Sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81649ae",
   "metadata": {},
   "source": [
    "# Data Dictionary \n",
    " \n",
    " The Data set contains 506 observations of House Price From Different Towns. Corresponding to each house price,data of other veriables is available on which price is suspected to depend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb7511",
   "metadata": {},
   "source": [
    "## About the dataset (House Pricing prediction data) \n",
    "\n",
    "**price:** Value of the house \n",
    "\n",
    "**crime_rate:** Crime rate in that neighborhood\n",
    "\n",
    "**resid_area:** Preporsion of residential area in the town\n",
    "\n",
    "**air_qual:** Quality of Air in that neighborhood\n",
    "\n",
    "**room_num:** Avearge number of rooms in houses of that locality\n",
    "\n",
    "**age:** How old is the house counstuction  in years\n",
    "\n",
    "**dist1:** Distance from employment hub 1\n",
    "\n",
    "**dist2:** Distance from employment hub 2\n",
    "\n",
    "**dist3:** Distance from employment hub 3\n",
    "\n",
    "**dist4:** Distance from employment hub 4\n",
    "\n",
    "**teachers:** Number of Teachers per 1000 population in the town\n",
    "\n",
    "**poor_prop:** Preportion of poor population in the town\n",
    "\n",
    "**airport:** Is there an airport in city? (Yes/No)\n",
    "\n",
    "**n_hos_beds:** Number of Hospital Beds per 1000 population in the town\n",
    "\n",
    "**n_hot_rooms:** Number of Hotel rooms per 1000 population in town\n",
    "\n",
    "**waterbody:** What type of natural fresh water sourcs is there in the city (Lake/River/Both/None)\n",
    "\n",
    "**rainfall:** The yearly average rainfall in centimeters\n",
    "\n",
    "**bus_ter:** Is there a bus terminal in city? (Yes/No)\n",
    "\n",
    "**parks:** Proportion of land assigned as park and green areas in town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b255754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 'Pandas' \n",
    "import pandas as pd \n",
    "\n",
    "# import 'Numpy' \n",
    "import numpy as np\n",
    "\n",
    "# import subpackage of Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# import 'Seaborn' \n",
    "import seaborn as sns\n",
    "\n",
    "# to suppress warnings \n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# display all columns of the dataframe\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# display all rows of the dataframe\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# set the plot size using 'rcParams'\n",
    "# once the plot size is set using 'rcParams', it sets the size of all the forthcoming plots in the file\n",
    "# pass width and height in inches to 'figure.figsize' \n",
    "plt.rcParams['figure.figsize'] = [15,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b39ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train-test split \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0539f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>airport</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>waterbody</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>bus_ter</th>\n",
       "      <th>parks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.01</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>YES</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.1920</td>\n",
       "      <td>River</td>\n",
       "      <td>23</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.049347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.06</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>NO</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.1728</td>\n",
       "      <td>Lake</td>\n",
       "      <td>42</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.046146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.97</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NO</td>\n",
       "      <td>7.394</td>\n",
       "      <td>101.1200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.045764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.93</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.96</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>YES</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.2672</td>\n",
       "      <td>Lake</td>\n",
       "      <td>45</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.047151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.37</td>\n",
       "      <td>5.86</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>NO</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.2896</td>\n",
       "      <td>Lake</td>\n",
       "      <td>55</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.039474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  crime_rate  resid_area  air_qual  room_num   age  dist1  dist2  \\\n",
       "0   24.0     0.00632       32.31     0.538     6.575  65.2   4.35   3.81   \n",
       "1   21.6     0.02731       37.07     0.469     6.421  78.9   4.99   4.70   \n",
       "2   34.7     0.02729       37.07     0.469     7.185  61.1   5.03   4.86   \n",
       "3   33.4     0.03237       32.18     0.458     6.998  45.8   6.21   5.93   \n",
       "4   36.2     0.06905       32.18     0.458     7.147  54.2   6.16   5.86   \n",
       "\n",
       "   dist3  dist4  teachers  poor_prop airport  n_hos_beds  n_hot_rooms  \\\n",
       "0   4.18   4.01      24.7       4.98     YES       5.480      11.1920   \n",
       "1   5.12   5.06      22.2       9.14      NO       7.332      12.1728   \n",
       "2   5.01   4.97      22.2       4.03      NO       7.394     101.1200   \n",
       "3   6.16   5.96      21.3       2.94     YES       9.268      11.2672   \n",
       "4   6.37   5.86      21.3       5.33      NO       8.824      11.2896   \n",
       "\n",
       "  waterbody  rainfall bus_ter     parks  \n",
       "0     River        23     YES  0.049347  \n",
       "1      Lake        42     YES  0.046146  \n",
       "2       NaN        38     YES  0.045764  \n",
       "3      Lake        45     YES  0.047151  \n",
       "4      Lake        55     YES  0.039474  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the csv file\n",
    "# store the data in 'df_houseprice'\n",
    "df_houseprice = pd.read_csv(\"House_Price.csv\")\n",
    "\n",
    "# display first five observations using head()\n",
    "df_houseprice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c941dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So as we see here Bus_ter column have only one unique value that means it wont usefull for our analysis\n",
    "# Axis  = 1  use for column 0 for row\n",
    "# inplace = True indecate permanat changes\n",
    "df_houseprice.drop(\"bus_ter\",axis =1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7467e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage of Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>waterbody</th>\n",
       "      <td>155</td>\n",
       "      <td>30.632411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hos_beds</th>\n",
       "      <td>8</td>\n",
       "      <td>1.581028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime_rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfall</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor_prop</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teachers</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_num</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_qual</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resid_area</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parks</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  Percentage of Missing Values\n",
       "waterbody      155                     30.632411\n",
       "n_hos_beds       8                      1.581028\n",
       "price            0                      0.000000\n",
       "crime_rate       0                      0.000000\n",
       "rainfall         0                      0.000000\n",
       "n_hot_rooms      0                      0.000000\n",
       "airport          0                      0.000000\n",
       "poor_prop        0                      0.000000\n",
       "teachers         0                      0.000000\n",
       "dist4            0                      0.000000\n",
       "dist3            0                      0.000000\n",
       "dist2            0                      0.000000\n",
       "dist1            0                      0.000000\n",
       "age              0                      0.000000\n",
       "room_num         0                      0.000000\n",
       "air_qual         0                      0.000000\n",
       "resid_area       0                      0.000000\n",
       "parks            0                      0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the variables on the basis of total null values in the variable\n",
    "# 'isnull().sum()' returns the number of missing values in each variable\n",
    "# 'ascending = False' sorts values in the descending order\n",
    "# the variable with highest number of missing values will appear first\n",
    "Total = df_houseprice.isnull().sum().sort_values(ascending=False)          \n",
    "\n",
    "# calculate percentage of missing values\n",
    "# 'ascending = False' sorts values in the descending order\n",
    "# the variable with highest percentage of missing values will appear first\n",
    "Percent = (df_houseprice.isnull().sum()*100/df_houseprice.isnull().count()).sort_values(ascending=False)   \n",
    "\n",
    "# concat the 'Total' and 'Percent' columns using 'concat' function\n",
    "# pass a list of column names in parameter 'keys' \n",
    "# 'axis = 1' concats along the columns\n",
    "missing_data = pd.concat([Total, Percent], axis = 1, keys = ['Total', 'Percentage of Missing Values'])    \n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a693c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houseprice.fillna(df_houseprice[\"n_hos_beds\"].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4610b86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percentage of Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime_rate</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainfall</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waterbody</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_hos_beds</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor_prop</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teachers</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dist1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_num</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_qual</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resid_area</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parks</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total  Percentage of Missing Values\n",
       "price            0                           0.0\n",
       "crime_rate       0                           0.0\n",
       "rainfall         0                           0.0\n",
       "waterbody        0                           0.0\n",
       "n_hot_rooms      0                           0.0\n",
       "n_hos_beds       0                           0.0\n",
       "airport          0                           0.0\n",
       "poor_prop        0                           0.0\n",
       "teachers         0                           0.0\n",
       "dist4            0                           0.0\n",
       "dist3            0                           0.0\n",
       "dist2            0                           0.0\n",
       "dist1            0                           0.0\n",
       "age              0                           0.0\n",
       "room_num         0                           0.0\n",
       "air_qual         0                           0.0\n",
       "resid_area       0                           0.0\n",
       "parks            0                           0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the variables on the basis of total null values in the variable\n",
    "# 'isnull().sum()' returns the number of missing values in each variable\n",
    "# 'ascending = False' sorts values in the descending order\n",
    "# the variable with highest number of missing values will appear first\n",
    "Total = df_houseprice.isnull().sum().sort_values(ascending=False)          \n",
    "\n",
    "# calculate percentage of missing values\n",
    "# 'ascending = False' sorts values in the descending order\n",
    "# the variable with highest percentage of missing values will appear first\n",
    "Percent = (df_houseprice.isnull().sum()*100/df_houseprice.isnull().count()).sort_values(ascending=False)   \n",
    "\n",
    "# concat the 'Total' and 'Percent' columns using 'concat' function\n",
    "# pass a list of column names in parameter 'keys' \n",
    "# 'axis = 1' concats along the columns\n",
    "missing_data = pd.concat([Total, Percent], axis = 1, keys = ['Total', 'Percentage of Missing Values'])    \n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf0e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the target variable 'Chance of Admit' in a dataframe 'df_target'\n",
    "df_target = df_houseprice['price']\n",
    "\n",
    "# store all the independent variables in a dataframe 'df_feature'\n",
    "# drop the column 'Chance of Admit' using drop()\n",
    "# 'axis = 1' drops the specified column\n",
    "df_feature = df_houseprice.drop('price', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aede4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>32.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.35</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.01</td>\n",
       "      <td>24.7</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.480</td>\n",
       "      <td>11.1920</td>\n",
       "      <td>23</td>\n",
       "      <td>0.049347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.06</td>\n",
       "      <td>22.2</td>\n",
       "      <td>9.14</td>\n",
       "      <td>7.332</td>\n",
       "      <td>12.1728</td>\n",
       "      <td>42</td>\n",
       "      <td>0.046146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>37.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.86</td>\n",
       "      <td>5.01</td>\n",
       "      <td>4.97</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.03</td>\n",
       "      <td>7.394</td>\n",
       "      <td>101.1200</td>\n",
       "      <td>38</td>\n",
       "      <td>0.045764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.21</td>\n",
       "      <td>5.93</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.96</td>\n",
       "      <td>21.3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>9.268</td>\n",
       "      <td>11.2672</td>\n",
       "      <td>45</td>\n",
       "      <td>0.047151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>32.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.16</td>\n",
       "      <td>5.86</td>\n",
       "      <td>6.37</td>\n",
       "      <td>5.86</td>\n",
       "      <td>21.3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>8.824</td>\n",
       "      <td>11.2896</td>\n",
       "      <td>55</td>\n",
       "      <td>0.039474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   crime_rate  resid_area  air_qual  room_num   age  dist1  dist2  dist3  \\\n",
       "0     0.00632       32.31     0.538     6.575  65.2   4.35   3.81   4.18   \n",
       "1     0.02731       37.07     0.469     6.421  78.9   4.99   4.70   5.12   \n",
       "2     0.02729       37.07     0.469     7.185  61.1   5.03   4.86   5.01   \n",
       "3     0.03237       32.18     0.458     6.998  45.8   6.21   5.93   6.16   \n",
       "4     0.06905       32.18     0.458     7.147  54.2   6.16   5.86   6.37   \n",
       "\n",
       "   dist4  teachers  poor_prop  n_hos_beds  n_hot_rooms  rainfall     parks  \n",
       "0   4.01      24.7       4.98       5.480      11.1920        23  0.049347  \n",
       "1   5.06      22.2       9.14       7.332      12.1728        42  0.046146  \n",
       "2   4.97      22.2       4.03       7.394     101.1200        38  0.045764  \n",
       "3   5.96      21.3       2.94       9.268      11.2672        45  0.047151  \n",
       "4   5.86      21.3       5.33       8.824      11.2896        55  0.039474  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the numerical features in the dataset\n",
    "# 'select_dtypes' is used to select the variables with given data type\n",
    "# 'include = [np.number]' will include all the numerical variables\n",
    "df_num = df_feature.select_dtypes(include = [np.number])\n",
    "\n",
    "# display numerical features\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f5433ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airport', 'waterbody'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the categorical features in the dataset\n",
    "# 'select_dtypes' is used to select the variables with given data type\n",
    "# 'include = [np.object]' will include all the categorical variables\n",
    "df_cat = df_feature.select_dtypes(include = ['object'])\n",
    "\n",
    "# display categorical features\n",
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba85f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 'get_dummies' from pandas to create dummy variables\n",
    "# use 'drop_first' to create (n-1) dummy variables\n",
    "dummy_var = pd.get_dummies(data = df_cat, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04d08b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import StandardScaler to perform scaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# initialize the standard scalar\n",
    "X_scaler = StandardScaler()\n",
    "\n",
    "# scale all the numerical columns\n",
    "# standardize all the columns of the dataframe 'df_num'\n",
    "num_scaled = X_scaler.fit_transform(df_num)\n",
    "\n",
    "# create a dataframe of scaled numerical variables\n",
    "# pass the required column names to the parameter 'columns'\n",
    "df_num_scaled = pd.DataFrame(num_scaled, columns = df_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a65a0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crime_rate</th>\n",
       "      <th>resid_area</th>\n",
       "      <th>air_qual</th>\n",
       "      <th>room_num</th>\n",
       "      <th>age</th>\n",
       "      <th>dist1</th>\n",
       "      <th>dist2</th>\n",
       "      <th>dist3</th>\n",
       "      <th>dist4</th>\n",
       "      <th>teachers</th>\n",
       "      <th>poor_prop</th>\n",
       "      <th>n_hos_beds</th>\n",
       "      <th>n_hot_rooms</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>parks</th>\n",
       "      <th>airport_YES</th>\n",
       "      <th>waterbody_Lake</th>\n",
       "      <th>waterbody_Lake and River</th>\n",
       "      <th>waterbody_River</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.179451</td>\n",
       "      <td>0.086032</td>\n",
       "      <td>0.103569</td>\n",
       "      <td>0.186459</td>\n",
       "      <td>1.459000</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>-1.653421</td>\n",
       "      <td>-0.353398</td>\n",
       "      <td>-1.294408</td>\n",
       "      <td>-0.480763</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.483280</td>\n",
       "      <td>0.508534</td>\n",
       "      <td>0.547446</td>\n",
       "      <td>0.687144</td>\n",
       "      <td>0.303094</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>-0.387954</td>\n",
       "      <td>-0.166000</td>\n",
       "      <td>0.225431</td>\n",
       "      <td>-0.782183</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.502269</td>\n",
       "      <td>0.584490</td>\n",
       "      <td>0.495503</td>\n",
       "      <td>0.644228</td>\n",
       "      <td>0.303094</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>-0.345589</td>\n",
       "      <td>16.828839</td>\n",
       "      <td>-0.094535</td>\n",
       "      <td>-0.818115</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.062454</td>\n",
       "      <td>1.092442</td>\n",
       "      <td>1.038545</td>\n",
       "      <td>1.116302</td>\n",
       "      <td>-0.113032</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>0.934910</td>\n",
       "      <td>-0.339029</td>\n",
       "      <td>0.465405</td>\n",
       "      <td>-0.687571</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.038717</td>\n",
       "      <td>1.059212</td>\n",
       "      <td>1.137709</td>\n",
       "      <td>1.068618</td>\n",
       "      <td>-0.113032</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>0.631526</td>\n",
       "      <td>-0.334750</td>\n",
       "      <td>1.265320</td>\n",
       "      <td>-1.410280</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   crime_rate  resid_area  air_qual  room_num       age     dist1     dist2  \\\n",
       "0   -0.419782   -1.287909 -0.144217  0.413672 -0.120013  0.179451  0.086032   \n",
       "1   -0.417339   -0.593381 -0.740262  0.194274  0.367166  0.483280  0.508534   \n",
       "2   -0.417342   -0.593381 -0.740262  1.282714 -0.265812  0.502269  0.584490   \n",
       "3   -0.416750   -1.306878 -0.835284  1.016303 -0.809889  1.062454  1.092442   \n",
       "4   -0.412482   -1.306878 -0.835284  1.228577 -0.511180  1.038717  1.059212   \n",
       "\n",
       "      dist3     dist4  teachers  poor_prop  n_hos_beds  n_hot_rooms  rainfall  \\\n",
       "0  0.103569  0.186459  1.459000  -1.075562   -1.653421    -0.353398 -1.294408   \n",
       "1  0.547446  0.687144  0.303094  -0.492439   -0.387954    -0.166000  0.225431   \n",
       "2  0.495503  0.644228  0.303094  -1.208727   -0.345589    16.828839 -0.094535   \n",
       "3  1.038545  1.116302 -0.113032  -1.361517    0.934910    -0.339029  0.465405   \n",
       "4  1.137709  1.068618 -0.113032  -1.026501    0.631526    -0.334750  1.265320   \n",
       "\n",
       "      parks  airport_YES  waterbody_Lake  waterbody_Lake and River  \\\n",
       "0 -0.480763         True           False                     False   \n",
       "1 -0.782183        False            True                     False   \n",
       "2 -0.818115        False           False                     False   \n",
       "3 -0.687571         True            True                     False   \n",
       "4 -1.410280        False            True                     False   \n",
       "\n",
       "   waterbody_River  \n",
       "0             True  \n",
       "1            False  \n",
       "2            False  \n",
       "3            False  \n",
       "4            False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat the dummy variables with numeric features to create a dataframe of all independent variables\n",
    "# 'axis=1' concats the dataframes along columns \n",
    "X = pd.concat([df_num_scaled, dummy_var], axis = 1)\n",
    "\n",
    "# display first five observations\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "902a93ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (404, 20)\n",
      "y_train (404,)\n",
      "X_test (102, 20)\n",
      "y_test (102,)\n"
     ]
    }
   ],
   "source": [
    "# import various functions from statsmodels\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# add a constant column to the dataframe\n",
    "# while using the 'Logit' method in the Statsmodels library, the method do not consider the intercept by default\n",
    "# we can add the intercept to the set of independent variables using 'add_constant()'\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# split data into train subset and test subset\n",
    "# set 'random_state' to generate the same dataset each time you run the code \n",
    "# 'test_size' returns the proportion of data to be included in the testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_target, random_state = 10, test_size = 0.2)\n",
    "\n",
    "# check the dimensions of the train & test subset using 'shape'\n",
    "# print dimension of train set\n",
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "\n",
    "# print dimension of test set\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b80609",
   "metadata": {},
   "source": [
    "# Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca58c5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 32.570727558966006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e87268",
   "metadata": {},
   "source": [
    "# Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a819a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 31.957909845850505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)  # alpha is the regularization strength\n",
    "\n",
    "# Fit the model to the training data\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = ridge_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d36a050",
   "metadata": {},
   "source": [
    "# Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f226678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 40.3630360157009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a Lasso regression model\n",
    "lasso_model = Lasso(alpha=1.0)  # alpha is the regularization strength\n",
    "\n",
    "# Fit the model to the training data\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = lasso_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a8125",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fbeb67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 37.528725490196074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a Decision Tree regression model\n",
    "tree_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit the model to the training data\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = tree_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef4327",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b434f481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 15.4789322745098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a Random Forest regression model\n",
    "forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = forest_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a3ded4",
   "metadata": {},
   "source": [
    "# Gaussian Process Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6157719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 737.9769607843136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a Gaussian Process regression model with an RBF kernel\n",
    "kernel = 1.0 * RBF(length_scale=1.0)\n",
    "gp_model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "gp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions, std_dev = gp_model.predict(X_test, return_std=True)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea466f",
   "metadata": {},
   "source": [
    "# Polynomial Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "465f8a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 77.20069982112238\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Generate polynomial features\n",
    "degree = 3  # degree of the polynomial\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Create a Polynomial Regression model\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd175fa6",
   "metadata": {},
   "source": [
    "# Neural Network Regression  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "985e8107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Praful Bhoyar\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Praful Bhoyar\\anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Praful Bhoyar\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "11/11 [==============================] - 2s 32ms/step - loss: 490.9160 - val_loss: 496.4388\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 441.1347 - val_loss: 441.3174\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 384.4519 - val_loss: 377.5191\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 318.6225 - val_loss: 303.4375\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 246.5522 - val_loss: 225.1302\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 174.1713 - val_loss: 156.1732\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 118.2030 - val_loss: 111.1539\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 82.6999 - val_loss: 89.4505\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 63.8044 - val_loss: 75.4843\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 49.7742 - val_loss: 64.0514\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 39.9995 - val_loss: 56.7630\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 32.4713 - val_loss: 51.8135\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 28.1196 - val_loss: 47.3604\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 24.8890 - val_loss: 44.4050\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 22.8303 - val_loss: 41.8949\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 21.3276 - val_loss: 40.4790\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 20.2317 - val_loss: 39.1421\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 19.2281 - val_loss: 38.2679\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 18.4080 - val_loss: 37.1165\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 17.7762 - val_loss: 36.6739\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 17.1905 - val_loss: 35.9573\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 16.6582 - val_loss: 35.2466\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.2179 - val_loss: 34.7660\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 16.0330 - val_loss: 33.5806\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.5378 - val_loss: 32.1013\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 15.1442 - val_loss: 32.3510\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.6297 - val_loss: 33.0938\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.4712 - val_loss: 33.0630\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 14.1330 - val_loss: 32.3058\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 13.7664 - val_loss: 31.1622\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 13.3923 - val_loss: 31.0601\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 13.2021 - val_loss: 31.2443\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 12.9345 - val_loss: 31.2766\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.7082 - val_loss: 31.0460\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 12.5203 - val_loss: 30.5050\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.3157 - val_loss: 31.4285\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.2570 - val_loss: 30.8390\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.2773 - val_loss: 32.7937\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 12.2217 - val_loss: 31.5311\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.8228 - val_loss: 31.1670\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 11.5060 - val_loss: 30.4372\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.4058 - val_loss: 28.6787\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.2951 - val_loss: 28.8698\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 11.0844 - val_loss: 29.2501\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.8331 - val_loss: 29.3426\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 10.7956 - val_loss: 29.0808\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 10.5279 - val_loss: 28.7129\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.5857 - val_loss: 30.0696\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 10.4915 - val_loss: 29.5745\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.2292 - val_loss: 28.5125\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.1163 - val_loss: 27.9292\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.9634 - val_loss: 27.9225\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.9114 - val_loss: 28.3571\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.7849 - val_loss: 27.8679\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 9.7290 - val_loss: 27.8403\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.5719 - val_loss: 27.5525\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 9.5371 - val_loss: 27.9302\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.4609 - val_loss: 27.8006\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 9.4365 - val_loss: 27.8964\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.2984 - val_loss: 27.3926\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.1592 - val_loss: 27.2260\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 9.0789 - val_loss: 26.5721\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 9.0879 - val_loss: 26.8932\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.9385 - val_loss: 27.2328\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8388 - val_loss: 27.1474\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8899 - val_loss: 26.9797\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.8956 - val_loss: 27.3629\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.7300 - val_loss: 28.0114\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.7353 - val_loss: 27.6092\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.6750 - val_loss: 26.5885\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5474 - val_loss: 26.4549\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 8.3861 - val_loss: 26.2888\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.5143 - val_loss: 27.5255\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.3096 - val_loss: 26.6396\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 7ms/step - loss: 8.3785 - val_loss: 26.3884\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.1541 - val_loss: 27.2031\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.1263 - val_loss: 27.9785\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.2215 - val_loss: 27.3045\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.1248 - val_loss: 25.4058\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.9761 - val_loss: 26.1465\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 8.0128 - val_loss: 26.0013\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.8155 - val_loss: 25.8987\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.8090 - val_loss: 26.2595\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.6859 - val_loss: 26.3288\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.5862 - val_loss: 26.2166\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.5494 - val_loss: 26.0909\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.6579 - val_loss: 26.5673\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.4252 - val_loss: 26.0381\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.3794 - val_loss: 26.1094\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 7.3682 - val_loss: 26.3806\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 7.3168 - val_loss: 26.3236\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.3066 - val_loss: 26.0339\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.5959 - val_loss: 24.1191\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.5906 - val_loss: 25.4736\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.3057 - val_loss: 25.1257\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.2112 - val_loss: 25.1172\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 7.0904 - val_loss: 25.7064\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 6.9806 - val_loss: 26.0108\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.9862 - val_loss: 25.7423\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 6.8637 - val_loss: 26.1396\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "Mean Squared Error: 16.09427414407775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n",
    "# Fit the model to the training data\n",
    "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecadf2e",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7ef8781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 26.713549019607836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a KNN regression model\n",
    "k = 5  # number of neighbors\n",
    "knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "\n",
    "# Fit the model to the training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505dc40",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fca7f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 46.2997253293128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined from train_test_split\n",
    "\n",
    "# Create a SVM regression model\n",
    "svm_model = SVR(kernel='rbf')  # 'rbf' kernel is commonly used for non-linear regression\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d6952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
